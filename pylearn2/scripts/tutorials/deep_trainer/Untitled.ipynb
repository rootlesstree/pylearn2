{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rr/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_neighbors=1, p=2, weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(y,gg.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.1298492 ,  0.13069262,  0.12919304,  0.12933622,  0.12987847,\n",
       "          0.12980035,  0.13000751,  0.1295728 ,  0.13025351,  0.13090743,\n",
       "          0.12947404,  0.12958416,  0.12787188,  0.13091456,  0.13185618,\n",
       "          0.13064505,  0.12947454,  0.13119055,  0.12970226,  0.13082989]]),\n",
       " array([[ 0.12962439,  0.13053459,  0.12901379,  0.1290788 ,  0.12976534,\n",
       "          0.12959154,  0.12979294,  0.12944969,  0.13009259,  0.1307194 ,\n",
       "          0.1292543 ,  0.12944066,  0.12771392,  0.13069144,  0.13171217,\n",
       "          0.13044065,  0.12931946,  0.13096522,  0.12955307,  0.13063631]]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.imshow(testset[2].X[0:1,:].reshape(100,100),cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a096512d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(100,100),cmap=cm.gray_r)\n",
    "plt.show()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = f(testset[2].X[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = encoder_models[1]\n",
    "X = model.get_input_space().make_theano_batch(batch_size=170)\n",
    "Y = model.reconstruct( X )\n",
    "f = theano.function( [X], Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "(None, <function _reconstructor at 0x7f6feada6aa0>, (<class 'theano.tensor.type.TensorType'>, <type 'object'>, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3c8763705048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylearn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"my_model.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_theano_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/rr/pylearn2/pylearn2/utils/serial.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(filepath, recurse_depth, retry)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjoblib_available\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/rr/anaconda/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reconstructor\u001b[1;34m(cls, base, state)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Support for pickling new-style objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_reconstructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: (None, <function _reconstructor at 0x7f6feada6aa0>, (<class 'theano.tensor.type.TensorType'>, <type 'object'>, None))"
     ]
    }
   ],
   "source": [
    "from pylearn2.utils import serial\n",
    "model_path = \"my_model.pkl\"\n",
    "model = serial.load( model_path )\n",
    "X = model.get_input_space().make_theano_batch(batch_size=1)\n",
    "Y = model.reconstruct( X )\n",
    "f = theano.function( [X], Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = encoder_models[0].get_input_space().make_theano_batch(batch_size=1)\n",
    "Y = encoder_models[0].reconstruct( X )\n",
    "f = theano.function( [X], Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylearn2.utils import serial\n",
    "model_path = \"my_model.pkl\"\n",
    "model = serial.load( model_path )\n",
    "X = model.get_input_space().make_theano_batch(batch_size=170)\n",
    "Y = model.encode( X )\n",
    "f = theano.function( [X], Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylearn2.models.model import Model\n",
    "from pylearn2.space import VectorSpace\n",
    "from pylearn2.models.mlp import PretrainedLayer\n",
    "import theano\n",
    "from theano import tensor\n",
    "from pylearn2.utils import sharedX\n",
    "import theano.tensor as T\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "__author__ = \"Li Yao\"\n",
    "\"\"\"\n",
    "See readme.txt\n",
    "\n",
    "A small example of how to glue shining features of pylearn2 together\n",
    "to train models layer by layer.\n",
    "\"\"\"\n",
    "\n",
    "MAX_EPOCHS_UNSUPERVISED = 1\n",
    "MAX_EPOCHS_SUPERVISED = 2\n",
    "\n",
    "from pylearn2.config import yaml_parse\n",
    "from pylearn2.corruption import BinomialCorruptor\n",
    "from pylearn2.corruption import GaussianCorruptor\n",
    "from pylearn2.costs.mlp import Default\n",
    "from pylearn2.models.autoencoder import Autoencoder, DenoisingAutoencoder\n",
    "from pylearn2.models.rbm import GaussianBinaryRBM\n",
    "from pylearn2.models.DRM import DeepEncoder\n",
    "from pylearn2.models.softmax_regression import SoftmaxRegression\n",
    "from pylearn2.training_algorithms.sgd import SGD\n",
    "from pylearn2.costs.autoencoder import MeanSquaredReconstructionError\n",
    "from pylearn2.termination_criteria import EpochCounter\n",
    "from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix\n",
    "from pylearn2.energy_functions.rbm_energy import GRBM_Type_1\n",
    "from pylearn2.blocks import StackedBlocks\n",
    "from pylearn2.datasets.transformer_dataset import TransformerDataset\n",
    "from pylearn2.costs.ebm_estimation import SMD\n",
    "from pylearn2.costs.DRM import DRMCost\n",
    "from pylearn2.training_algorithms.sgd import MonitorBasedLRAdjuster\n",
    "from pylearn2.train import Train\n",
    "from optparse import OptionParser\n",
    "from pylearn2.datasets.c3 import load_data\n",
    "\n",
    "import numpy\n",
    "\n",
    "MAX_EPOCHS_UNSUPERVISED = 1\n",
    "MAX_EPOCHS_SUPERVISED = 2\n",
    "\n",
    "\n",
    "class ToyDataset(DenseDesignMatrix):\n",
    "    def __init__(self):\n",
    "        # simulated random dataset\n",
    "        rng = numpy.random.RandomState(seed=42)\n",
    "        data = rng.normal(size=(1000, 10))\n",
    "        self.y = numpy.random.binomial(1, 0.5, (1000, 1))\n",
    "        super(ToyDataset, self).__init__(X=data, y=self.y, y_labels=2)\n",
    "\n",
    "def get_dataset_toy():\n",
    "    \"\"\"\n",
    "    The toy dataset is only meant to used for testing pipelines.\n",
    "    Do not try to visualize weights on it. It is not picture and\n",
    "    has no color channel info to support visualization\n",
    "    \"\"\"\n",
    "    trainset = ToyDataset()\n",
    "    testset = ToyDataset()\n",
    "\n",
    "    return trainset, testset\n",
    "\n",
    "def get_dataset_cifar10():\n",
    "\n",
    "    print('loading CIFAR-10 dataset...')\n",
    "\n",
    "    # We create the dataset by parsing YAML strings describing the dataset.\n",
    "    # The yaml parser will automatically tag trainset and testset with a\n",
    "    # yaml_src field containing the YAML string that was used to specify them.\n",
    "    # This is useful because later the training algorithm can store this YAML\n",
    "    # string in the saved model to efficiently describe exactly what data it\n",
    "    # was trained on.\n",
    "    template = \\\n",
    "\"\"\"!obj:pylearn2.datasets.cifar10.CIFAR10 {\n",
    "which_set: %s,\n",
    "center: 1,\n",
    "rescale: 1,\n",
    "}\"\"\"\n",
    "    trainset = yaml_parse.load(template % \"train\")\n",
    "    testset = yaml_parse.load(template % \"test\")\n",
    "\n",
    "    print('...done loading CIFAR-10.')\n",
    "\n",
    "    return trainset, testset\n",
    "\n",
    "def get_dataset_mnist():\n",
    "\n",
    "    print('loading MNIST dataset...')\n",
    "\n",
    "    # We create the dataset by parsing YAML strings describing the dataset.\n",
    "    # The yaml parser will automatically tag trainset and testset with a\n",
    "    # yaml_src field containing the YAML string that was used to specify them.\n",
    "    # This is useful because later the training algorithm can store this YAML\n",
    "    # string in the saved model to efficiently describe exactly what data it\n",
    "    # was trained on.\n",
    "    template = \\\n",
    "\"\"\"!obj:pylearn2.datasets.mnist.MNIST {\n",
    "which_set: %s,\n",
    "}\"\"\"\n",
    "    trainset = yaml_parse.load(template % \"train\")\n",
    "    testset = yaml_parse.load(template % \"test\")\n",
    "\n",
    "    print('...done loading MNIST.')\n",
    "\n",
    "    return trainset, testset\n",
    "\n",
    "def get_autoencoder(structure):\n",
    "    n_input, n_output = structure\n",
    "    config = {\n",
    "        'nhid': n_output,\n",
    "        'nvis': n_input,\n",
    "        'tied_weights': True,\n",
    "        'act_enc': 'sigmoid',\n",
    "        'act_dec': 'sigmoid',\n",
    "        'irange': 0.001,\n",
    "    }\n",
    "    return Autoencoder(**config)\n",
    "\n",
    "def get_denoising_autoencoder(structure):\n",
    "    n_input, n_output = structure\n",
    "    curruptor = BinomialCorruptor(corruption_level=0.5)\n",
    "    config = {\n",
    "        'corruptor': curruptor,\n",
    "        'nhid': n_output,\n",
    "        'nvis': n_input,\n",
    "        'tied_weights': True,\n",
    "        'act_enc': 'sigmoid',\n",
    "        'act_dec': 'sigmoid',\n",
    "        'irange': 0.001,\n",
    "    }\n",
    "    return DenoisingAutoencoder(**config)\n",
    "\n",
    "def get_grbm(structure):\n",
    "    n_input, n_output = structure\n",
    "    config = {\n",
    "        'nvis': n_input,\n",
    "        'nhid': n_output,\n",
    "        \"irange\" : 0.05,\n",
    "        \"energy_function_class\" : GRBM_Type_1,\n",
    "        \"learn_sigma\" : True,\n",
    "        \"init_sigma\" : .4,\n",
    "        \"init_bias_hid\" : -2.,\n",
    "        \"mean_vis\" : False,\n",
    "        \"sigma_lr_scale\" : 1e-3\n",
    "        }\n",
    "\n",
    "    return GaussianBinaryRBM(**config)\n",
    "\n",
    "def get_logistic_regressor(structure):\n",
    "    n_input, n_output = structure\n",
    "\n",
    "    layer = SoftmaxRegression(n_classes=n_output, irange=0.02, nvis=n_input)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def get_layer_trainer_logistic(layer, trainset):\n",
    "    # configs on sgd\n",
    "\n",
    "    config = {'learning_rate': 0.1,\n",
    "              'cost' : Default(),\n",
    "              'batch_size': 10,\n",
    "              'monitoring_batches': 10,\n",
    "              'monitoring_dataset': trainset,\n",
    "              'termination_criterion': EpochCounter(max_epochs=MAX_EPOCHS_SUPERVISED),\n",
    "              'update_callbacks': None\n",
    "              }\n",
    "\n",
    "    train_algo = SGD(**config)\n",
    "    model = layer\n",
    "    return Train(model = model,\n",
    "            dataset = trainset,\n",
    "            algorithm = train_algo,\n",
    "            extensions = None)\n",
    "\n",
    "def get_layer_trainer_sgd_autoencoder(layer, trainset):\n",
    "    # configs on sgd\n",
    "    train_algo = SGD(\n",
    "            learning_rate = 0.1,\n",
    "              cost =  DRMCost(),\n",
    "              batch_size =  10,\n",
    "              monitoring_batches = 10,\n",
    "              monitoring_dataset =  trainset,\n",
    "              termination_criterion = EpochCounter(max_epochs=10),\n",
    "              update_callbacks =  None\n",
    "              )\n",
    "\n",
    "    model = layer\n",
    "    extensions = None\n",
    "    return Train(model = model,\n",
    "            algorithm = train_algo,\n",
    "            extensions = extensions,\n",
    "            save_path='my_model.pkl'\n",
    "            ,save_freq=1,\n",
    "            dataset = trainset)\n",
    "\n",
    "def get_layer_trainer_sgd_rbm(layer, trainset,epochs):\n",
    "    train_algo = SGD(\n",
    "        learning_rate = 1e-1,\n",
    "        batch_size =  5,\n",
    "        #\"batches_per_iter\" : 2000,\n",
    "        monitoring_batches =  20,\n",
    "        monitoring_dataset =  trainset,\n",
    "        cost = SMD(corruptor=GaussianCorruptor(stdev=0.4)),\n",
    "        termination_criterion =  EpochCounter(max_epochs=epochs),\n",
    "        )\n",
    "    model = layer\n",
    "    extensions = [MonitorBasedLRAdjuster()]\n",
    "    return Train(model = model, algorithm = train_algo,\n",
    "                 save_path='grbm.pkl',save_freq=1,\n",
    "                 extensions = extensions, dataset = trainset)\n",
    "\n",
    "\n",
    "    \n",
    "def maind(args=None):\n",
    "    #trainset, testset, = get_dataset_mnist()\n",
    "    trainset, testset = load_data()\n",
    "    n_output = 10\n",
    "    \n",
    "    design_matrix = trainset.get_design_matrix()\n",
    "    n_input = design_matrix.shape[1]\n",
    "\n",
    "    # build layers\n",
    "    layers = []\n",
    "    structure = [[n_input, 50], [50, 10], [10, 5],[5, n_input]]\n",
    "    # layer 0: gaussianRBM\n",
    "    layers.append(get_grbm(structure[0]))\n",
    "    # layer 1: denoising AE\n",
    "    layers.append(get_grbm(structure[1]))\n",
    "    # layer 2: AE\n",
    "    layers.append(get_grbm(structure[2]))\n",
    "\n",
    "    # layer 3: logistic regression used in supervised training\n",
    "    #layers.append(get_logistic_regressor(structure[3]))\n",
    "\n",
    "    # construct training sets for different layers\n",
    "    trainset = [ trainset ,\n",
    "                TransformerDataset( raw = trainset, transformer = layers[0] ),\n",
    "                TransformerDataset( raw = trainset, transformer = StackedBlocks( layers[0:2] )),\n",
    "                TransformerDataset( raw = trainset, transformer = StackedBlocks( layers[0:3] ))  \n",
    "                ]\n",
    "    # construct layer trainers\n",
    "    layer_trainers = []\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[0], trainset[0],20))\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[1], trainset[1],5))\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[2], trainset[2],5))\n",
    "    #layer_trainers.append(get_layer_trainer_logistic(layers[3], trainset[3]))\n",
    "\n",
    "\n",
    "    \n",
    "    # unsupervised pretraining\n",
    "    for i, layer_trainer in enumerate(layer_trainers[0:3]):\n",
    "        print('-----------------------------------')\n",
    "        print(' Unsupervised training layer %d, %s'%(i, layers[i].__class__))\n",
    "        print('-----------------------------------')\n",
    "        layer_trainer.main_loop()\n",
    "\n",
    "\n",
    "    encoder = DeepEncoder(layers)\n",
    "\n",
    "    print('\\n')\n",
    "    print('------------------------------------------------------')\n",
    "    print(' Unsupervised training done! Start Fine-tuing training...')\n",
    "    print('------------------------------------------------------')\n",
    "    print('\\n')\n",
    "\n",
    "    # supervised training\n",
    "    #layer_trainers[-1].main_loop()\n",
    "    trainer = get_layer_trainer_sgd_autoencoder(encoder,trainset[0])\n",
    "    trainer.main_loop()\n",
    "    return encoder,layers,trainset\n",
    "\n",
    "def encoder_model(trainset):\n",
    "    design_matrix = trainset.get_design_matrix()\n",
    "    n_input = design_matrix.shape[1]\n",
    "    layers = []\n",
    "    structure = [[n_input, 50], [50, 10], [10, 5],[5, n_input]]\n",
    "    # layer 0: gaussianRBM\n",
    "    layers.append(get_grbm(structure[0]))\n",
    "    # layer 1: denoising AE\n",
    "    layers.append(get_grbm(structure[1]))\n",
    "    # layer 2: AE\n",
    "    layers.append(get_grbm(structure[2]))\n",
    "    \n",
    "    trainset = [ trainset ,\n",
    "                TransformerDataset( raw = trainset, transformer = layers[0] ),\n",
    "                TransformerDataset( raw = trainset, transformer = StackedBlocks( layers[0:2] )),\n",
    "                TransformerDataset( raw = trainset, transformer = StackedBlocks( layers[0:3] ))  \n",
    "                ]\n",
    "\n",
    "    # construct layer trainers\n",
    "    layer_trainers = []\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[0], trainset[0],100))\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[1], trainset[1],5))\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[2], trainset[2],5))\n",
    "    #layer_trainers.append(get_layer_trainer_logistic(layers[3], trainset[3]))\n",
    "    # unsupervised pretraining\n",
    "    for i, layer_trainer in enumerate(layer_trainers[0:3]):\n",
    "        print('-----------------------------------')\n",
    "        print(' Unsupervised training layer %d, %s'%(i, layers[i].__class__))\n",
    "        print('-----------------------------------')\n",
    "        layer_trainer.main_loop()\n",
    "\n",
    "    encoder = DeepEncoder(layers)\n",
    "\n",
    "    print('\\n')\n",
    "    print('------------------------------------------------------')\n",
    "    print(' Unsupervised training done! Start Fine-tuing training...')\n",
    "    print('------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    # supervised training\n",
    "    #layer_trainers[-1].main_loop()\n",
    "    trainer = get_layer_trainer_sgd_autoencoder(encoder,trainset[0])\n",
    "    trainer.main_loop()\n",
    "    return encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.1\n",
      "\tbias_vis: 0.1\n",
      "\tbias_hid: 0.1\n",
      "\tsigma_driver: 0.1\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.552615 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.025898 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 83\n",
      "Compiling accum done. Time elapsed: 0.548078 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.0\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 0.984289745445\n",
      "\th_mean: 0.137645287166\n",
      "\th_min: 1.25870640472e-15\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 13.8339956107\n",
      "\treconstruction_error: 3533.89394917\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 0.120989 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 12\n",
      "\tExamples seen: 58\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00099799019\n",
      "\tbias_hid_min: -2.00312403152\n",
      "\tbias_vis_max: 0.00797905821426\n",
      "\tbias_vis_mean: 0.00475474451634\n",
      "\tbias_vis_min: 0.000518298506086\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.105314056826\n",
      "\th_min: 1.92457082689e-20\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 12.6704358485\n",
      "\treconstruction_error: 3247.18868214\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.120989\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 1.088951 seconds\n",
      "Time this epoch: 0.124558 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 24\n",
      "\tExamples seen: 116\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00125056366\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0156153102372\n",
      "\tbias_vis_mean: 0.00923822120398\n",
      "\tbias_vis_min: 0.000845690377847\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.12000040621\n",
      "\th_min: 1.84900933347e-20\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 11.5119831269\n",
      "\treconstruction_error: 2955.21435751\n",
      "\ttotal_seconds_last_epoch: 1.32626\n",
      "\ttraining_seconds_this_epoch: 0.124558\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.426164 seconds\n",
      "Time this epoch: 0.147912 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 36\n",
      "\tExamples seen: 174\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00138090249\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0229234095612\n",
      "\tbias_vis_mean: 0.013437451112\n",
      "\tbias_vis_min: 0.000947000574207\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000065218\n",
      "\th_min: 2.02576767543e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 10.3777930271\n",
      "\treconstruction_error: 2667.95264025\n",
      "\ttotal_seconds_last_epoch: 0.697267\n",
      "\ttraining_seconds_this_epoch: 0.147912\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.420387 seconds\n",
      "Time this epoch: 0.125929 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 48\n",
      "\tExamples seen: 232\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00140534296\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0297516018302\n",
      "\tbias_vis_mean: 0.0173921522098\n",
      "\tbias_vis_min: 0.00112522531779\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000020177\n",
      "\th_min: 2.088190279e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 9.38197862526\n",
      "\treconstruction_error: 2414.99649183\n",
      "\ttotal_seconds_last_epoch: 0.714944\n",
      "\ttraining_seconds_this_epoch: 0.125929\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.222424 seconds\n",
      "Time this epoch: 0.134276 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 60\n",
      "\tExamples seen: 290\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00144246132\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.036061881728\n",
      "\tbias_vis_mean: 0.0210694796898\n",
      "\tbias_vis_min: 0.00121974989984\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000016807\n",
      "\th_min: 2.14579471953e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 8.51590573233\n",
      "\treconstruction_error: 2194.5180613\n",
      "\ttotal_seconds_last_epoch: 0.464437\n",
      "\ttraining_seconds_this_epoch: 0.134276\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223569 seconds\n",
      "Time this epoch: 0.130310 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 6\n",
      "\tBatches seen: 72\n",
      "\tExamples seen: 348\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00148389908\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0420411434443\n",
      "\tbias_vis_mean: 0.0245103304811\n",
      "\tbias_vis_min: 0.00131815449702\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000681\n",
      "\th_min: 2.19959681297e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 7.7594498695\n",
      "\treconstruction_error: 2001.27136131\n",
      "\ttotal_seconds_last_epoch: 0.47399\n",
      "\ttraining_seconds_this_epoch: 0.13031\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223757 seconds\n",
      "Time this epoch: 0.127518 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 7\n",
      "\tBatches seen: 84\n",
      "\tExamples seen: 406\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00148609085\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0476368188141\n",
      "\tbias_vis_mean: 0.027728544668\n",
      "\tbias_vis_min: 0.00139493610773\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000656\n",
      "\th_min: 2.24948871663e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 7.0945450091\n",
      "\treconstruction_error: 1831.62025338\n",
      "\ttotal_seconds_last_epoch: 0.469681\n",
      "\ttraining_seconds_this_epoch: 0.127518\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223663 seconds\n",
      "Time this epoch: 0.228163 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 8\n",
      "\tBatches seen: 96\n",
      "\tExamples seen: 464\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00149676735\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0529009714795\n",
      "\tbias_vis_mean: 0.0307411098722\n",
      "\tbias_vis_min: 0.00147188995264\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000591\n",
      "\th_min: 2.2962770363e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 6.51455747115\n",
      "\treconstruction_error: 1683.07695847\n",
      "\ttotal_seconds_last_epoch: 0.46972\n",
      "\ttraining_seconds_this_epoch: 0.228163\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223791 seconds\n",
      "Time this epoch: 0.152802 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 9\n",
      "\tBatches seen: 108\n",
      "\tExamples seen: 522\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00151204417\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0578621341424\n",
      "\tbias_vis_mean: 0.0335612231095\n",
      "\tbias_vis_min: 0.00155428142356\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000341\n",
      "\th_min: 2.34000453843e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 6.00455724376\n",
      "\treconstruction_error: 1552.64303996\n",
      "\ttotal_seconds_last_epoch: 0.568781\n",
      "\ttraining_seconds_this_epoch: 0.152802\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223911 seconds\n",
      "Time this epoch: 0.119231 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 10\n",
      "\tBatches seen: 120\n",
      "\tExamples seen: 580\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.0015121979\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0624108220663\n",
      "\tbias_vis_mean: 0.0362024705199\n",
      "\tbias_vis_min: 0.00160114268243\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000338\n",
      "\th_min: 2.38113692213e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 5.55922141629\n",
      "\treconstruction_error: 1438.50254679\n",
      "\ttotal_seconds_last_epoch: 0.493053\n",
      "\ttraining_seconds_this_epoch: 0.119231\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223778 seconds\n",
      "Time this epoch: 0.151822 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 11\n",
      "\tBatches seen: 132\n",
      "\tExamples seen: 638\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.0015212446\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.066643301472\n",
      "\tbias_vis_mean: 0.0386765534525\n",
      "\tbias_vis_min: 0.00168605792924\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000047\n",
      "\th_min: 2.41981629235e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 5.16843615831\n",
      "\treconstruction_error: 1338.19496883\n",
      "\ttotal_seconds_last_epoch: 0.458881\n",
      "\ttraining_seconds_this_epoch: 0.151822\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223364 seconds\n",
      "Time this epoch: 0.147079 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 12\n",
      "\tBatches seen: 144\n",
      "\tExamples seen: 696\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00152721926\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0706734943857\n",
      "\tbias_vis_mean: 0.0409924398158\n",
      "\tbias_vis_min: 0.00171963752633\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000019\n",
      "\th_min: 2.45637986985e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 4.82554054861\n",
      "\treconstruction_error: 1250.1424134\n",
      "\ttotal_seconds_last_epoch: 0.491778\n",
      "\ttraining_seconds_this_epoch: 0.147079\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223926 seconds\n",
      "Time this epoch: 0.123174 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 13\n",
      "\tBatches seen: 156\n",
      "\tExamples seen: 754\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155066418\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.074456069679\n",
      "\tbias_vis_mean: 0.0431596056088\n",
      "\tbias_vis_min: 0.00181610673122\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000015\n",
      "\th_min: 2.49089622101e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 4.52480018027\n",
      "\treconstruction_error: 1172.85776824\n",
      "\ttotal_seconds_last_epoch: 0.486018\n",
      "\ttraining_seconds_this_epoch: 0.123174\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223821 seconds\n",
      "Time this epoch: 0.167981 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 14\n",
      "\tBatches seen: 168\n",
      "\tExamples seen: 812\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155087872\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0780355697908\n",
      "\tbias_vis_mean: 0.0451891043785\n",
      "\tbias_vis_min: 0.00185766124724\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000015\n",
      "\th_min: 2.523817982e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 4.26112009071\n",
      "\treconstruction_error: 1105.06955748\n",
      "\ttotal_seconds_last_epoch: 0.462657\n",
      "\ttraining_seconds_this_epoch: 0.167981\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.223988 seconds\n",
      "Time this epoch: 0.155698 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 15\n",
      "\tBatches seen: 180\n",
      "\tExamples seen: 870\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155764975\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0813345732285\n",
      "\tbias_vis_mean: 0.0470918607553\n",
      "\tbias_vis_min: 0.00191278903316\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000012\n",
      "\th_min: 2.55526206283e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 4.02940131327\n",
      "\treconstruction_error: 1045.56314916\n",
      "\ttotal_seconds_last_epoch: 0.507162\n",
      "\ttraining_seconds_this_epoch: 0.155698\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.224155 seconds\n",
      "Time this epoch: 0.116759 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 16\n",
      "\tBatches seen: 192\n",
      "\tExamples seen: 928\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155808351\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0844259522869\n",
      "\tbias_vis_mean: 0.0488718893706\n",
      "\tbias_vis_min: 0.00196795367725\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000012\n",
      "\th_min: 2.58544656956e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.82734007788\n",
      "\treconstruction_error: 993.499017027\n",
      "\ttotal_seconds_last_epoch: 0.495304\n",
      "\ttraining_seconds_this_epoch: 0.116759\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.224590 seconds\n",
      "Time this epoch: 0.196357 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 17\n",
      "\tBatches seen: 204\n",
      "\tExamples seen: 986\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155808204\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0873066891643\n",
      "\tbias_vis_mean: 0.050540314493\n",
      "\tbias_vis_min: 0.0019947899768\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000012\n",
      "\th_min: 2.61447683182e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.64964157028\n",
      "\treconstruction_error: 947.779934282\n",
      "\ttotal_seconds_last_epoch: 0.456893\n",
      "\ttraining_seconds_this_epoch: 0.196357\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.224413 seconds\n",
      "Time this epoch: 0.115329 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 18\n",
      "\tBatches seen: 216\n",
      "\tExamples seen: 1044\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155825408\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0899471536736\n",
      "\tbias_vis_mean: 0.0521049300049\n",
      "\tbias_vis_min: 0.00206511567447\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000011\n",
      "\th_min: 2.64261918416e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.49352322317\n",
      "\treconstruction_error: 907.624840746\n",
      "\ttotal_seconds_last_epoch: 0.536239\n",
      "\ttraining_seconds_this_epoch: 0.115329\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.299945 seconds\n",
      "Time this epoch: 0.142974 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 19\n",
      "\tBatches seen: 228\n",
      "\tExamples seen: 1102\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00155822936\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0924284592653\n",
      "\tbias_vis_mean: 0.0535706607399\n",
      "\tbias_vis_min: 0.00211754049617\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000011\n",
      "\th_min: 2.66968941037e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.35619894498\n",
      "\treconstruction_error: 872.323290683\n",
      "\ttotal_seconds_last_epoch: 0.530872\n",
      "\ttraining_seconds_this_epoch: 0.142974\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.224977 seconds\n",
      "Time this epoch: 0.158069 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 20\n",
      "\tBatches seen: 240\n",
      "\tExamples seen: 1160\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00157187083\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0948064187695\n",
      "\tbias_vis_mean: 0.0549423011607\n",
      "\tbias_vis_min: 0.00214475815987\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000008\n",
      "\th_min: 2.69587073714e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.23540921257\n",
      "\treconstruction_error: 841.208767236\n",
      "\ttotal_seconds_last_epoch: 0.48365\n",
      "\ttraining_seconds_this_epoch: 0.158069\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.224964 seconds\n",
      "Time this epoch: 0.149260 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 21\n",
      "\tBatches seen: 252\n",
      "\tExamples seen: 1218\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00157205902\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0970625523294\n",
      "\tbias_vis_mean: 0.0562287063202\n",
      "\tbias_vis_min: 0.00218013586\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.72128379475e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.12880270867\n",
      "\treconstruction_error: 813.838494006\n",
      "\ttotal_seconds_last_epoch: 0.499254\n",
      "\ttraining_seconds_this_epoch: 0.14926\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.224934 seconds\n",
      "Time this epoch: 0.131958 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 22\n",
      "\tBatches seen: 264\n",
      "\tExamples seen: 1276\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00157203345\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.0992138042742\n",
      "\tbias_vis_mean: 0.0574308041477\n",
      "\tbias_vis_min: 0.00214621445664\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.74601283405e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 3.03572922245\n",
      "\treconstruction_error: 789.873392597\n",
      "\ttotal_seconds_last_epoch: 0.489892\n",
      "\ttraining_seconds_this_epoch: 0.131958\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225277 seconds\n",
      "Time this epoch: 0.143793 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 23\n",
      "\tBatches seen: 276\n",
      "\tExamples seen: 1334\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00158429366\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.101101202761\n",
      "\tbias_vis_mean: 0.0585605410963\n",
      "\tbias_vis_min: 0.00216928002367\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.77046619521e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.95369238703\n",
      "\treconstruction_error: 768.814889196\n",
      "\ttotal_seconds_last_epoch: 0.472901\n",
      "\ttraining_seconds_this_epoch: 0.143793\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225512 seconds\n",
      "Time this epoch: 0.126377 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 24\n",
      "\tBatches seen: 288\n",
      "\tExamples seen: 1392\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00158429\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.102899025534\n",
      "\tbias_vis_mean: 0.0596433650396\n",
      "\tbias_vis_min: 0.00227921469829\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.79473832745e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.88058408996\n",
      "\treconstruction_error: 750.008551034\n",
      "\ttotal_seconds_last_epoch: 0.483963\n",
      "\ttraining_seconds_this_epoch: 0.126377\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225372 seconds\n",
      "Time this epoch: 0.123467 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 25\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 1450\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00158429076\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.10463435799\n",
      "\tbias_vis_mean: 0.0606315008451\n",
      "\tbias_vis_min: 0.00231526542633\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.81825657503e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.81760560719\n",
      "\treconstruction_error: 733.81206527\n",
      "\ttotal_seconds_last_epoch: 0.467478\n",
      "\ttraining_seconds_this_epoch: 0.123467\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225354 seconds\n",
      "Time this epoch: 0.124176 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 26\n",
      "\tBatches seen: 312\n",
      "\tExamples seen: 1508\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00159011847\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.106249014049\n",
      "\tbias_vis_mean: 0.0615574932528\n",
      "\tbias_vis_min: 0.0023564456253\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.84143237368e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.76223134794\n",
      "\treconstruction_error: 719.616526928\n",
      "\ttotal_seconds_last_epoch: 0.465241\n",
      "\ttraining_seconds_this_epoch: 0.124176\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225348 seconds\n",
      "Time this epoch: 0.119086 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 27\n",
      "\tBatches seen: 324\n",
      "\tExamples seen: 1566\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00159002317\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.107790767941\n",
      "\tbias_vis_mean: 0.0624265200993\n",
      "\tbias_vis_min: 0.00239405117572\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.86438655876e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.71328543095\n",
      "\treconstruction_error: 707.112157637\n",
      "\ttotal_seconds_last_epoch: 0.466128\n",
      "\ttraining_seconds_this_epoch: 0.119086\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225580 seconds\n",
      "Time this epoch: 0.123431 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 28\n",
      "\tBatches seen: 336\n",
      "\tExamples seen: 1624\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.0015899787\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.10925130961\n",
      "\tbias_vis_mean: 0.0632407689001\n",
      "\tbias_vis_min: 0.00242709192311\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 2.88703680108e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.67018750585\n",
      "\treconstruction_error: 696.139748738\n",
      "\ttotal_seconds_last_epoch: 0.46623\n",
      "\ttraining_seconds_this_epoch: 0.123431\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225779 seconds\n",
      "Time this epoch: 0.125532 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 29\n",
      "\tBatches seen: 348\n",
      "\tExamples seen: 1682\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.0015899547\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.110525880322\n",
      "\tbias_vis_mean: 0.0640065169934\n",
      "\tbias_vis_min: 0.00249498660438\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000008\n",
      "\th_min: 2.91015496707e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.63323327594\n",
      "\treconstruction_error: 686.651052296\n",
      "\ttotal_seconds_last_epoch: 0.47049\n",
      "\ttraining_seconds_this_epoch: 0.125532\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.226914 seconds\n",
      "Time this epoch: 0.123374 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 30\n",
      "\tBatches seen: 360\n",
      "\tExamples seen: 1740\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00158990218\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.111765586982\n",
      "\tbias_vis_mean: 0.0647220381926\n",
      "\tbias_vis_min: 0.00252186483276\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000008\n",
      "\th_min: 2.93256698928e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.59992738405\n",
      "\treconstruction_error: 678.18585845\n",
      "\ttotal_seconds_last_epoch: 0.472892\n",
      "\ttraining_seconds_this_epoch: 0.123374\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.235971 seconds\n",
      "Time this epoch: 0.123020 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 31\n",
      "\tBatches seen: 372\n",
      "\tExamples seen: 1798\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00158987984\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.112862902917\n",
      "\tbias_vis_mean: 0.0653941832456\n",
      "\tbias_vis_min: 0.00257738895834\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000008\n",
      "\th_min: 2.95510190619e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.57091820096\n",
      "\treconstruction_error: 670.834939824\n",
      "\ttotal_seconds_last_epoch: 0.50248\n",
      "\ttraining_seconds_this_epoch: 0.12302\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.226481 seconds\n",
      "Time this epoch: 0.131012 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 32\n",
      "\tBatches seen: 384\n",
      "\tExamples seen: 1856\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00160280852\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.113916331843\n",
      "\tbias_vis_mean: 0.0660230051582\n",
      "\tbias_vis_min: 0.00259059441383\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000006\n",
      "\th_min: 2.97721599997e-23\n",
      "\tlearning_rate: 0.1\n",
      "\tobjective: 2.54547305929\n",
      "\treconstruction_error: 664.262886719\n",
      "\ttotal_seconds_last_epoch: 0.494382\n",
      "\ttraining_seconds_this_epoch: 0.131012\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.101000\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.226431 seconds\n",
      "Time this epoch: 0.231406 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 33\n",
      "\tBatches seen: 396\n",
      "\tExamples seen: 1914\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.001602802\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.115022901491\n",
      "\tbias_vis_mean: 0.0666163867148\n",
      "\tbias_vis_min: 0.0025766520378\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000006\n",
      "\th_min: 2.99949436347e-23\n",
      "\tlearning_rate: 0.101\n",
      "\tobjective: 2.52202923237\n",
      "\treconstruction_error: 658.452320757\n",
      "\ttotal_seconds_last_epoch: 0.493218\n",
      "\ttraining_seconds_this_epoch: 0.231406\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.102010\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225620 seconds\n",
      "Time this epoch: 0.254366 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 34\n",
      "\tBatches seen: 408\n",
      "\tExamples seen: 1972\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00160272825\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.116010894858\n",
      "\tbias_vis_mean: 0.0671783153876\n",
      "\tbias_vis_min: 0.00258680712348\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000006\n",
      "\th_min: 3.02198745819e-23\n",
      "\tlearning_rate: 0.10201\n",
      "\tobjective: 2.50174105429\n",
      "\treconstruction_error: 653.311546222\n",
      "\ttotal_seconds_last_epoch: 0.603015\n",
      "\ttraining_seconds_this_epoch: 0.254366\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.103030\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225846 seconds\n",
      "Time this epoch: 0.226049 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 35\n",
      "\tBatches seen: 420\n",
      "\tExamples seen: 2030\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00162309413\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.116978926571\n",
      "\tbias_vis_mean: 0.0677075446694\n",
      "\tbias_vis_min: 0.00257777528036\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000006\n",
      "\th_min: 3.04450258075e-23\n",
      "\tlearning_rate: 0.1030301\n",
      "\tobjective: 2.4834924864\n",
      "\treconstruction_error: 648.730240659\n",
      "\ttotal_seconds_last_epoch: 0.631449\n",
      "\ttraining_seconds_this_epoch: 0.226049\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.104060\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225971 seconds\n",
      "Time this epoch: 0.298333 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 36\n",
      "\tBatches seen: 432\n",
      "\tExamples seen: 2088\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.0016230519\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.117721139965\n",
      "\tbias_vis_mean: 0.0682122486564\n",
      "\tbias_vis_min: 0.00259070309704\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000006\n",
      "\th_min: 3.06749291143e-23\n",
      "\tlearning_rate: 0.104060401\n",
      "\tobjective: 2.46745163865\n",
      "\treconstruction_error: 644.704039592\n",
      "\ttotal_seconds_last_epoch: 0.597799\n",
      "\ttraining_seconds_this_epoch: 0.298333\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.105101\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.226277 seconds\n",
      "Time this epoch: 0.139777 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 37\n",
      "\tBatches seen: 444\n",
      "\tExamples seen: 2146\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00162243296\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.118564592385\n",
      "\tbias_vis_mean: 0.0686846407242\n",
      "\tbias_vis_min: 0.00260704861506\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 3.0908299449e-23\n",
      "\tlearning_rate: 0.10510100501\n",
      "\tobjective: 2.45320318859\n",
      "\treconstruction_error: 641.212480806\n",
      "\ttotal_seconds_last_epoch: 0.66469\n",
      "\ttraining_seconds_this_epoch: 0.139777\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.106152\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.225644 seconds\n",
      "Time this epoch: 0.263892 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 38\n",
      "\tBatches seen: 456\n",
      "\tExamples seen: 2204\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00162242261\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.119268944704\n",
      "\tbias_vis_mean: 0.0691326616116\n",
      "\tbias_vis_min: 0.00261449712731\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 3.11420865607e-23\n",
      "\tlearning_rate: 0.10615201506\n",
      "\tobjective: 2.4406906619\n",
      "\treconstruction_error: 638.074503841\n",
      "\ttotal_seconds_last_epoch: 0.508541\n",
      "\ttraining_seconds_this_epoch: 0.263892\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.107214\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.226272 seconds\n",
      "Time this epoch: 0.153497 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 39\n",
      "\tBatches seen: 468\n",
      "\tExamples seen: 2262\n",
      "\tbias_hid_max: -1.99974968531\n",
      "\tbias_hid_mean: -2.00164406642\n",
      "\tbias_hid_min: -2.00464707405\n",
      "\tbias_vis_max: 0.11999975323\n",
      "\tbias_vis_mean: 0.0695551912317\n",
      "\tbias_vis_min: 0.00260455302066\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.120000000007\n",
      "\th_min: 3.13778472652e-23\n",
      "\tlearning_rate: 0.107213535211\n",
      "\tobjective: 2.42905498716\n",
      "\treconstruction_error: 635.295583614\n",
      "\ttotal_seconds_last_epoch: 0.62428\n",
      "\ttraining_seconds_this_epoch: 0.153497\n",
      "monitoring channel is objective\n",
      "growing learning rate to 0.108286\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 0.226792 seconds\n",
      "Time this epoch: 0.151461 seconds\n"
     ]
    }
   ],
   "source": [
    "Training,Testing = load_data()\n",
    "encoder_models = []\n",
    "for train in Training:\n",
    "    encoder_models.append(encoder_model(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = encoder_models[0].get_input_space().make_theano_batch(batch_size=47)\n",
    "Y = encoder_models[0].reconstruct( X )\n",
    "f1 = theano.function( [X], Y )\n",
    "Y2 = encoder_models[1].reconstruct( X )\n",
    "f2 = theano.function( [X], Y2 )\n",
    "Y3 = encoder_models[2].reconstruct( X )\n",
    "f3 = theano.function( [X], Y3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R1 = f1(testset[1].X)\n",
    "R2 = f2(testset[1].X)\n",
    "R3 = f3(testset[1].X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9535.1425419064435"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((R3 - testset[1].X)**2).sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ..., \n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pylearn2.models.DRM.DeepEncoder at 0x7fbd937f93d0>,\n",
       " <pylearn2.models.DRM.DeepEncoder at 0x7fbd8d81d290>,\n",
       " <pylearn2.models.DRM.DeepEncoder at 0x7fbd7c604c10>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = encoder._params[1]\n",
    "b = encoder._params[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theano.tensor.var.TensorVariable"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "type(T.scalar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "b = copy.deepcopy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theano.tensor.sharedvar.TensorSharedVariable"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoder._params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylearn2.utils import sharedX\n",
    "a =sharedX(0,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset,testset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1210fe8d1ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = T.scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 18])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w = np.asarray([[1,2,3],[4,5,6],[7,8,9]])\n",
    "w.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17842313812242389"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
